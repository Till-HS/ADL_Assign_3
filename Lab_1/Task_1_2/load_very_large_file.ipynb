{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pandas(data, columns):\n",
    "    df_ = pd.DataFrame(columns=columns)\n",
    "    data['Sentence'] = data['Sentence'].str.lower()\n",
    "    data['Sentence'] = data['Sentence'].replace('[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', '', regex=True)                      # remove emails\n",
    "    data['Sentence'] = data['Sentence'].replace('((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', regex=True)    # remove IP address\n",
    "    data['Sentence'] = data['Sentence'].str.replace('[^\\w\\s]','')                                                       # remove special characters\n",
    "    data['Sentence'] = data['Sentence'].replace('\\d', '', regex=True)                                                   # remove numbers\n",
    "    for index, row in data.iterrows():\n",
    "        word_tokens = word_tokenize(row['Sentence'])\n",
    "        filtered_sent = [w for w in word_tokens if not w in stopwords.words('english')]\n",
    "        df_.loc[len(df_)] = {\n",
    "            \"index\": row['index'],\n",
    "            \"Class\": row['Class'],\n",
    "            \"Sentence\": \" \".join(filtered_sent)\n",
    "        }\n",
    "    return data\n",
    "\n",
    "# If this is the primary file that is executed (ie not an import of another file)\n",
    "if __name__ == \"__main__\":\n",
    "    # get data, pre-process and split\n",
    "    training_xlarge = pd.read_csv(\"train.csv\", delimiter=',', header=None).sample(200000)            # choose a sample of size 200000\n",
    "    #test_xlarge = pd.read_csv(\"test.csv\", delimiter=',', header=None)\n",
    "    training_xlarge.columns = [ 'Class', 'Title', 'Sentence']\n",
    "    training_xlarge['index'] = training_xlarge.index                                          # add new column index\n",
    "    columns = ['index', 'Class', 'Sentence']\n",
    "    training_xlarge = preprocess_pandas(training_xlarge, columns)                             # pre-process\n",
    "    \n",
    "    training_data_xl, validation_data_xl, training_labels_xl, validation_labels_xl = train_test_split( # split the data into training, validation, and test splits\n",
    "        training_xlarge['Sentence'].values.astype('U'),\n",
    "        training_xlarge['Class'].values.astype('int32'),\n",
    "        test_size=0.10,\n",
    "        random_state=0,\n",
    "        shuffle=True\n",
    "    )\n",
    "    training_labels_xl -= 1                       # mapping from {1, 2} to {0, 1}\n",
    "    validation_labels_xl -= 1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
